{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "y67VGwJ-8Or3",
        "outputId": "2adaeffa-9ac7-461c-b0ec-2b35ddad2010"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.18)\n",
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.11/dist-packages (0.3.17)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (3.4.1)\n",
            "Requirement already satisfied: pinecone-client in /usr/local/lib/python3.11/dist-packages (5.0.1)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.11/dist-packages (1.0.1)\n",
            "Requirement already satisfied: typing in /usr/local/lib/python3.11/dist-packages (3.7.4.3)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (2.10.6)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.34 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.34)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.6 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.6)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.5)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.37)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (3.11.11)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain) (9.0.0)\n",
            "Requirement already satisfied: numpy<2,>=1.26.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.7.1)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.4.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.48.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.5.1+cu124)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.28.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.1.0)\n",
            "Requirement already satisfied: certifi>=2019.11.17 in /usr/local/lib/python3.11/dist-packages (from pinecone-client) (2025.1.31)\n",
            "Requirement already satisfied: pinecone-plugin-inference<2.0.0,>=1.0.3 in /usr/local/lib/python3.11/dist-packages (from pinecone-client) (1.1.0)\n",
            "Requirement already satisfied: pinecone-plugin-interface<0.0.8,>=0.0.7 in /usr/local/lib/python3.11/dist-packages (from pinecone-client) (0.0.7)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.11/dist-packages (from pinecone-client) (4.12.2)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from pinecone-client) (2.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic) (2.27.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.17.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.34->langchain) (1.33)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.5)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.34->langchain) (3.0.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain langchain-community sentence-transformers pinecone-client python-dotenv typing pydantic"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q sentence-transformers transformers torch"
      ],
      "metadata": {
        "id": "G9HZoKBUb8id"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages\n",
        "!pip install -q langchain-cohere cohere langchain pinecone-client"
      ],
      "metadata": {
        "collapsed": true,
        "id": "olkG2hZN-jZ4"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import LLMChain, PromptTemplate\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.llms import HuggingFaceHub\n",
        "from langchain.vectorstores import Pinecone as LangchainPinecone\n",
        "from pinecone import Pinecone, ServerlessSpec\n",
        "from typing import List, Dict\n",
        "import json\n",
        "import os"
      ],
      "metadata": {
        "id": "0MMXfiScEdBv"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set API keys\n",
        "HUGGINGFACE_TOKEN = \"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\"\n",
        "PINECONE_API_KEY = \"pcsk_44R4w_9mXN3CD1j1kqzSjUzzwYkDJePke4GioyChxpYWmK48Ro369U4vGmEKd5rtpFkLi\"\n",
        "\n",
        "# Set environment variables\n",
        "os.environ[\"HUGGINGFACE_API_TOKEN\"] = HUGGINGFACE_TOKEN\n",
        "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = HUGGINGFACE_TOKEN\n",
        "os.environ[\"PINECONE_API_KEY\"] = PINECONE_API_KEY\n",
        "os.environ[\"PINECONE_ENVIRONMENT\"] = \"gcp-starter\""
      ],
      "metadata": {
        "id": "spy6OyJtEd2W"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade pinecone-client"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vT8l_arbFKgQ",
        "outputId": "c10cf050-67ee-4ff9-abee-54180c386584"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pinecone-client in /usr/local/lib/python3.11/dist-packages (5.0.1)\n",
            "Requirement already satisfied: certifi>=2019.11.17 in /usr/local/lib/python3.11/dist-packages (from pinecone-client) (2025.1.31)\n",
            "Requirement already satisfied: pinecone-plugin-inference<2.0.0,>=1.0.3 in /usr/local/lib/python3.11/dist-packages (from pinecone-client) (1.1.0)\n",
            "Requirement already satisfied: pinecone-plugin-interface<0.0.8,>=0.0.7 in /usr/local/lib/python3.11/dist-packages (from pinecone-client) (0.0.7)\n",
            "Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.11/dist-packages (from pinecone-client) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.11/dist-packages (from pinecone-client) (4.12.2)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from pinecone-client) (2.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize HuggingFaceEmbeddings\n",
        "embedding_model = HuggingFaceEmbeddings(\n",
        "    model_name=\"sentence-transformers/all-mpnet-base-v2\",\n",
        "    model_kwargs={\"token\": HUGGINGFACE_TOKEN}\n",
        ")\n",
        "\n",
        "# Initialize Pinecone\n",
        "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
        "\n",
        "index_name = \"cv-db\"\n",
        "\n",
        "# Initialize Pinecone vector store with LangChain\n",
        "vectorstore = LangchainPinecone.from_existing_index(\n",
        "    index_name=index_name,\n",
        "    embedding=embedding_model,\n",
        ")\n",
        "\n",
        "# Initialize LLM with specific task\n",
        "llm = HuggingFaceHub(\n",
        "    repo_id=\"google/flan-t5-large\",\n",
        "    huggingfacehub_api_token=HUGGINGFACE_TOKEN,\n",
        "    task=\"text2text-generation\",\n",
        "    model_kwargs={\n",
        "        \"temperature\": 0.7,\n",
        "        \"max_length\": 512\n",
        "    }\n",
        ")"
      ],
      "metadata": {
        "id": "q5oOZUELGAzs"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "index = pc.Index(\"cv-db\")\n",
        "\n",
        "def get_embedding(text):\n",
        "    \"\"\"\n",
        "    Function to get the embeddings of a text\n",
        "    :params text: the text to encode\n",
        "    :return: the embeddings\n",
        "    \"\"\"\n",
        "    model = SentenceTransformer(\"sentence-transformers/all-mpnet-base-v2\")\n",
        "\n",
        "    embeddings = model.encode([text])\n",
        "    return embeddings[0]"
      ],
      "metadata": {
        "id": "6vIOJfyO3Hxf"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.vectorstores import Pinecone as LangchainPinecone\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.llms import HuggingFaceHub\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "from pinecone import Pinecone\n",
        "from typing import Dict\n",
        "\n",
        "# Initialize HuggingFace Embeddings\n",
        "embedding_model = HuggingFaceEmbeddings(\n",
        "    model_name=\"sentence-transformers/all-mpnet-base-v2\",\n",
        "    model_kwargs={\"token\": HUGGINGFACE_TOKEN}\n",
        ")\n",
        "\n",
        "# Initialize Pinecone\n",
        "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
        "\n",
        "index_name = \"cv-db\"\n",
        "\n",
        "# Initialize Pinecone vector store with LangChain\n",
        "vectorstore = LangchainPinecone.from_existing_index(\n",
        "    index_name=index_name,\n",
        "    embedding=embedding_model,\n",
        "    text_key=\"page_content\"\n",
        ")\n",
        "\n",
        "# Initialize LLM\n",
        "llm = HuggingFaceHub(\n",
        "    repo_id=\"google/flan-t5-large\",\n",
        "    huggingfacehub_api_token=HUGGINGFACE_TOKEN,\n",
        "    task=\"text2text-generation\",\n",
        "    model_kwargs={\"temperature\": 0.7, \"max_length\": 512}\n",
        ")\n",
        "\n",
        "# Define prompt template\n",
        "resume_query_template = \"\"\"\n",
        "Given the following job requirements:\n",
        "{job_requirements}\n",
        "\n",
        "And the candidate information:\n",
        "{candidate_info}\n",
        "\n",
        "Please analyze and provide:\n",
        "1. Match percentage\n",
        "2. Key qualifications that align with requirements\n",
        "3. Any gaps in qualifications\n",
        "4. Overall recommendation\n",
        "\n",
        "Response:\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    template=resume_query_template,\n",
        "    input_variables=[\"job_requirements\", \"candidate_info\"]\n",
        ")\n",
        "\n",
        "class ResumeSearchBot:\n",
        "    def __init__(self):\n",
        "        self.llm_chain = LLMChain(llm=llm, prompt=prompt)\n",
        "        self.vectorstore = vectorstore\n",
        "\n",
        "    def search_candidates(self, query, top_k=5):\n",
        "        \"\"\"Searches the Pinecone index for the most relevant candidates.\"\"\"\n",
        "        query_embed = get_embedding(query).tolist()  # Convert NumPy array to list\n",
        "\n",
        "        results = index.query(\n",
        "            vector=query_embed,\n",
        "            top_k=top_k,\n",
        "            include_metadata=True\n",
        "        )\n",
        "\n",
        "        # Extract candidate information\n",
        "        candidates = []\n",
        "        print(results)  # Debugging output to inspect results\n",
        "\n",
        "        for match in results[\"matches\"]:  # Correctly loop through retrieved matches\n",
        "            metadata = match[\"metadata\"]  # Extract metadata\n",
        "            candidate_info = f\"Content: {metadata.get('content', 'N/A')}\\n\" \\\n",
        "                            f\"Original File: {metadata.get('original_file', 'N/A')}\\n\" \\\n",
        "                            f\"Score: {match.get('score', 'N/A')}\"  # Include similarity score\n",
        "\n",
        "            candidates.append(candidate_info)\n",
        "\n",
        "        return candidates\n",
        "\n",
        "\n",
        "    def add_resume(self, resume_text: str, metadata: Dict = None):\n",
        "        \"\"\"Add a resume to the vector store\"\"\"\n",
        "        try:\n",
        "            # Add text to vector store\n",
        "            ids = self.vectorstore.add_texts(\n",
        "                texts=[resume_text],\n",
        "                metadatas=[metadata] if metadata else None\n",
        "            )\n",
        "            return ids[0]  # Return the first ID\n",
        "        except Exception as e:\n",
        "            print(f\"Error adding resume: {str(e)}\")\n",
        "            return None\n",
        "\n",
        "def test_bot():\n",
        "    bot = ResumeSearchBot()\n",
        "\n",
        "    print(\"\\nTesting search functionality...\")\n",
        "    query = \"Looking for a developer with Docker, AWS knowledge\"\n",
        "    results = bot.search_candidates(query)\n",
        "\n",
        "    print(\"\\nSearch Results:\")\n",
        "    for idx, candidate in enumerate(results, 1):\n",
        "        print(f\"\\nCandidate {idx}:\")\n",
        "        print(candidate)  # Correctly displaying retrieved candidate info\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    test_bot()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BiKa-yQ18r2L",
        "outputId": "9e7b4f0a-b9ba-4a75-ab48-e8fea38dc8a6"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Testing search functionality...\n",
            "{'matches': [{'id': 'extraction_summary.csv_chunk_131',\n",
            "              'metadata': {'content': '. Skilled in managing real-time data '\n",
            "                                      'processing with Apache Kafka, '\n",
            "                                      'containerization with Docker, and '\n",
            "                                      'version control with Git. Qualified in '\n",
            "                                      'Kubernetes for container orchestration '\n",
            "                                      'and Tableau for data visualization. '\n",
            "                                      'Adept at working with databases, '\n",
            "                                      'including MongoDB and PostgreSQL, and '\n",
            "                                      'experienced in deploying applications '\n",
            "                                      'on Linux environments. Proven ability '\n",
            "                                      'to integrate workflow automation using '\n",
            "                                      'Camunda and dynamic templating with '\n",
            "                                      'Jinja2. Known for optimizing '\n",
            "                                      'performance, ensuring code quality, and '\n",
            "                                      'collaborating effectively with '\n",
            "                                      'cross-functional teams. KEY '\n",
            "                                      'COMPETENCIES + Data Visualization '\n",
            "                                      '(Matplotlib/Seaborn)',\n",
            "                           'original_file': 'extraction_summary.csv'},\n",
            "              'score': 0.590333581,\n",
            "              'values': []},\n",
            "             {'id': 'Eman Ismail Muhammad Resume_SW_ML.txt_chunk_1',\n",
            "              'metadata': {'content': '. Skilled in managing real-time data '\n",
            "                                      'processing with Apache Kafka, '\n",
            "                                      'containerization with Docker, and '\n",
            "                                      'version control with Git. Qualified in '\n",
            "                                      'Kubernetes for container orchestration '\n",
            "                                      'and Tableau for data visualization. '\n",
            "                                      'Adept at working with databases, '\n",
            "                                      'including MongoDB and PostgreSQL, and '\n",
            "                                      'experienced in deploying applications '\n",
            "                                      'on Linux environments. Proven ability '\n",
            "                                      'to integrate workflow automation using '\n",
            "                                      'Camunda and dynamic templating with '\n",
            "                                      'Jinja2. Known for optimizing '\n",
            "                                      'performance, ensuring code quality, and '\n",
            "                                      'collaborating effectively with '\n",
            "                                      'cross-functional teams. KEY '\n",
            "                                      'COMPETENCIES + Data Visualization '\n",
            "                                      '(Matplotlib/Seaborn)',\n",
            "                           'original_file': 'Eman Ismail Muhammad '\n",
            "                                            'Resume_SW_ML.txt'},\n",
            "              'score': 0.590333581,\n",
            "              'values': []},\n",
            "             {'id': 'extraction_summary.csv_chunk_23',\n",
            "              'metadata': {'content': '. Docker, AWS, Azure DevOps, Azure '\n",
            "                                      'Repos, Git, GitHub, Jenkins, Linux '\n",
            "                                      '(Redhat, Ubuntu) Backend Development: ° '\n",
            "                                      'Django, Flask, Node.js, RESTful APIs, '\n",
            "                                      'GraphQL, MySQL, PostgreSQL, Redis, '\n",
            "                                      'Swagger, Postman Front-end & UI/UX: ° '\n",
            "                                      'React.js, Angular, SCSS, Bootstrap, '\n",
            "                                      'Material Ul, Figma, Adobe XD Business '\n",
            "                                      'Intelligence & Data Visualization: ° '\n",
            "                                      'Power BI, Kibana, Dash (Plotly), '\n",
            "                                      'Seaborn AWS Machine Learning Engineer '\n",
            "                                      'Nano-degree Udacity « 2022 React '\n",
            "                                      'Nano-degree Udacity + 2021 Selected '\n",
            "                                      'Projects Virtual Assistant - (Django, '\n",
            "                                      'React, Wav2Lip, Speech Recognition) © '\n",
            "                                      '2023 « Developed a React-based frontend '\n",
            "                                      'for a voice-interactive virtual '\n",
            "                                      'assistant, integrating Wav2Lip for '\n",
            "                                      'realistic lip synchronization and',\n",
            "                           'original_file': 'extraction_summary.csv'},\n",
            "              'score': 0.503868461,\n",
            "              'values': []},\n",
            "             {'id': 'SW_MLEngineer_OmarMarie.txt_chunk_8',\n",
            "              'metadata': {'content': '. Docker, AWS, Azure DevOps, Azure '\n",
            "                                      'Repos, Git, GitHub, Jenkins, Linux '\n",
            "                                      '(Redhat, Ubuntu) Backend Development: ° '\n",
            "                                      'Django, Flask, Node.js, RESTful APIs, '\n",
            "                                      'GraphQL, MySQL, PostgreSQL, Redis, '\n",
            "                                      'Swagger, Postman Front-end & UI/UX: ° '\n",
            "                                      'React.js, Angular, SCSS, Bootstrap, '\n",
            "                                      'Material Ul, Figma, Adobe XD Business '\n",
            "                                      'Intelligence & Data Visualization: ° '\n",
            "                                      'Power BI, Kibana, Dash (Plotly), '\n",
            "                                      'Seaborn AWS Machine Learning Engineer '\n",
            "                                      'Nano-degree Udacity « 2022 React '\n",
            "                                      'Nano-degree Udacity + 2021 Selected '\n",
            "                                      'Projects Virtual Assistant - (Django, '\n",
            "                                      'React, Wav2Lip, Speech Recognition) © '\n",
            "                                      '2023 « Developed a React-based frontend '\n",
            "                                      'for a voice-interactive virtual '\n",
            "                                      'assistant, integrating Wav2Lip for '\n",
            "                                      'realistic lip synchronization and',\n",
            "                           'original_file': 'SW_MLEngineer_OmarMarie.txt'},\n",
            "              'score': 0.503868461,\n",
            "              'values': []},\n",
            "             {'id': 'SW_MLEngineer_RohandaHamed.txt_chunk_1',\n",
            "              'metadata': {'content': '. Mashreq Arabia, Alexandria, Egypt '\n",
            "                                      'Python software developer July 2020 – '\n",
            "                                      'March 2021 Created an inventory '\n",
            "                                      'management system “3alababak” using '\n",
            "                                      'Django Restful Created an E-invoicing '\n",
            "                                      'system in Django “BooksM8” Contributed '\n",
            "                                      'in building HR management system '\n",
            "                                      '“PeopleM8” using Django Used HTML ,CSS '\n",
            "                                      'and JavaScript to create templates to '\n",
            "                                      'fit clients’ needs ICT CUBE, Maadi - '\n",
            "                                      'Cairo, Egypt September 2018 – May 2019 '\n",
            "                                      'Junior software developer Worked on '\n",
            "                                      'creating a test automation framework. '\n",
            "                                      'Learned to use Docker, Django and git. '\n",
            "                                      'Learned to write unit tests in python '\n",
            "                                      'and to ensure high code coverage. '\n",
            "                                      'Gained experience in dealing with SQl '\n",
            "                                      'and no SQL database such as '\n",
            "                                      'Elasticsearch',\n",
            "                           'original_file': 'SW_MLEngineer_RohandaHamed.txt'},\n",
            "              'score': 0.465921611,\n",
            "              'values': []}],\n",
            " 'namespace': '',\n",
            " 'usage': {'read_units': 6}}\n",
            "\n",
            "Search Results:\n",
            "\n",
            "Candidate 1:\n",
            "Content: . Skilled in managing real-time data processing with Apache Kafka, containerization with Docker, and version control with Git. Qualified in Kubernetes for container orchestration and Tableau for data visualization. Adept at working with databases, including MongoDB and PostgreSQL, and experienced in deploying applications on Linux environments. Proven ability to integrate workflow automation using Camunda and dynamic templating with Jinja2. Known for optimizing performance, ensuring code quality, and collaborating effectively with cross-functional teams. KEY COMPETENCIES + Data Visualization (Matplotlib/Seaborn)\n",
            "Original File: extraction_summary.csv\n",
            "Score: 0.590333581\n",
            "\n",
            "Candidate 2:\n",
            "Content: . Skilled in managing real-time data processing with Apache Kafka, containerization with Docker, and version control with Git. Qualified in Kubernetes for container orchestration and Tableau for data visualization. Adept at working with databases, including MongoDB and PostgreSQL, and experienced in deploying applications on Linux environments. Proven ability to integrate workflow automation using Camunda and dynamic templating with Jinja2. Known for optimizing performance, ensuring code quality, and collaborating effectively with cross-functional teams. KEY COMPETENCIES + Data Visualization (Matplotlib/Seaborn)\n",
            "Original File: Eman Ismail Muhammad Resume_SW_ML.txt\n",
            "Score: 0.590333581\n",
            "\n",
            "Candidate 3:\n",
            "Content: . Docker, AWS, Azure DevOps, Azure Repos, Git, GitHub, Jenkins, Linux (Redhat, Ubuntu) Backend Development: ° Django, Flask, Node.js, RESTful APIs, GraphQL, MySQL, PostgreSQL, Redis, Swagger, Postman Front-end & UI/UX: ° React.js, Angular, SCSS, Bootstrap, Material Ul, Figma, Adobe XD Business Intelligence & Data Visualization: ° Power BI, Kibana, Dash (Plotly), Seaborn AWS Machine Learning Engineer Nano-degree Udacity « 2022 React Nano-degree Udacity + 2021 Selected Projects Virtual Assistant - (Django, React, Wav2Lip, Speech Recognition) © 2023 « Developed a React-based frontend for a voice-interactive virtual assistant, integrating Wav2Lip for realistic lip synchronization and\n",
            "Original File: extraction_summary.csv\n",
            "Score: 0.503868461\n",
            "\n",
            "Candidate 4:\n",
            "Content: . Docker, AWS, Azure DevOps, Azure Repos, Git, GitHub, Jenkins, Linux (Redhat, Ubuntu) Backend Development: ° Django, Flask, Node.js, RESTful APIs, GraphQL, MySQL, PostgreSQL, Redis, Swagger, Postman Front-end & UI/UX: ° React.js, Angular, SCSS, Bootstrap, Material Ul, Figma, Adobe XD Business Intelligence & Data Visualization: ° Power BI, Kibana, Dash (Plotly), Seaborn AWS Machine Learning Engineer Nano-degree Udacity « 2022 React Nano-degree Udacity + 2021 Selected Projects Virtual Assistant - (Django, React, Wav2Lip, Speech Recognition) © 2023 « Developed a React-based frontend for a voice-interactive virtual assistant, integrating Wav2Lip for realistic lip synchronization and\n",
            "Original File: SW_MLEngineer_OmarMarie.txt\n",
            "Score: 0.503868461\n",
            "\n",
            "Candidate 5:\n",
            "Content: . Mashreq Arabia, Alexandria, Egypt Python software developer July 2020 – March 2021 Created an inventory management system “3alababak” using Django Restful Created an E-invoicing system in Django “BooksM8” Contributed in building HR management system “PeopleM8” using Django Used HTML ,CSS and JavaScript to create templates to fit clients’ needs ICT CUBE, Maadi - Cairo, Egypt September 2018 – May 2019 Junior software developer Worked on creating a test automation framework. Learned to use Docker, Django and git. Learned to write unit tests in python and to ensure high code coverage. Gained experience in dealing with SQl and no SQL database such as Elasticsearch\n",
            "Original File: SW_MLEngineer_RohandaHamed.txt\n",
            "Score: 0.465921611\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## API Endpoints"
      ],
      "metadata": {
        "id": "dsKokcF78xkF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from fastapi import FastAPI\n",
        "\n",
        "app = FastAPI()\n",
        "bot = ResumeSearchBot()\n",
        "\n",
        "@app.post(\"/search_candidates\")\n",
        "async def search_candidates(query: str):\n",
        "    return bot.search_candidates(query)\n",
        "\n",
        "@app.get(\"/candidate/{candidate_id}\")\n",
        "async def get_candidate(candidate_id: str):\n",
        "    return bot.get_candidate_details(candidate_id)"
      ],
      "metadata": {
        "id": "wW5RGycy8tAf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}